
realtime_crawler : {
  max_queue_length:100;
  realtime_indexer : [
    {ip:"127.0.0.1"; port:5102;},
  ];

  host_use_proxy_file:"crawler/realtime_crawler/data/proxy";
  max_duration_inqueue:600000;
  handler:{
    status_prefix:"output/status";
    saver_timespan:3600;
    default_queue_ip:"127.0.0.1";
    default_queue_port:40000;
    default_queue_tube:"resource";
  };

  job_manager: {
    queue_ip:"127.0.0.1";
    queue_port:40000;
    queue_tube:"";
    max_task_onetime:100;
    max_retry_times:5;
  };
  
  page_crawler : {
    connect_timeout_in_seconds: 10; # 建立连接的时长
    transfer_timeout_in_seconds: 60; # 传输时间时长
    low_speed_limit_in_bytes_per_second:500; # "慢连接速度上限"
    low_speed_duration_in_seconds: 20;  # 慢连接持续时间上限
    user_agent : "Mozilla/5.0";
    max_redir_times: 32; # 最大跳转次数
    enable_curl_debug: 0;
  };

  load_controller : {
    default_max_qps:3;
    default_max_connections:6;  # 在一个  ip 上的链接数限制
    max_connections_in_all:1000; # 所有 fetcher 总体的连接数限制
    max_holdon_duration_after_failed: 10000;
    # number mili-second's to hold on, if failed fecth on one ip.
    min_holdon_duration_after_failed: 5000;
    failed_times_threadhold:10; # 失败多少此之后放弃抓取

    # 如果在某 ip 上连续失败多少此， 则此 ip 之上所有链接将被丢弃
    max_failed_times:100;
    check_frequency: 15; # 每爬去多少次， 检测一次 QPS 限制
    ip_load_file: "data/ip_load"; # QPS 限制文件
  };

  proxy: {
    list : [
      "socks5://192.168.11.40",
      "socks5://192.168.11.41",
      "socks5://192.168.11.42",
    ];
    max_successive_failures : 15;
    holdon_duration_after_failures: 60;
  };
};