
realtime_crawler : {
  host_use_proxy_file:"data/sites_through_proxy";
  max_queue_length:3000;
  max_duration_inqueue:240000;
  percentage_use_proxy:95;  # 在列表当中的多少使用代理
  handler:{
    status_prefix:"output/status";
    saver_timespan:1800;
    default_queue_ip:"10.115.86.99";
    default_queue_port:20071;
    default_queue_tube:"";
  };

  job_manager: {
    queue_ip:"180.153.227.166";
    queue_port:20080;
    queue_tube:"";
    holdon_when_jobfull:100;
    reserve_job_timeout:1;
    max_retry_times:5;
  };
  
  page_crawler : {
    connect_timeout_in_seconds: 80; # 建立连接的时长
    transfer_timeout_in_seconds: 80; # 传输时间时长
    low_speed_limit_in_bytes_per_second:500; # "慢连接速度上限"
    low_speed_duration_in_seconds: 80;  # 慢连接持续时间上限
    user_agent : "360Spider";
    user_agent_p : "Mozilla/5.0";
    max_redir_times: 32; # 最大跳转次数
    enable_curl_debug: 0;
    https_supported_urls_filepath: "data/url_support_https.txt";
    client_redirect_urls_filepath: "data/client_redirect.txt";
  };

  load_controller : {
    default_max_qps:5;
    default_max_connections:8;  # 在一个  ip 上的链接数限制
    max_connections_in_all:1800; # 所有 fetcher 总体的连接数限制
    max_holdon_duration_after_failed: 100000;
    # number mili-second's to hold on, if failed fecth on one ip.
    min_holdon_duration_after_failed: 5000;
    failed_times_threadhold:10; # 失败多少此之后放弃抓取

    # 如果在某 ip 上连续失败多少此， 则此 ip 之上所有链接将被丢弃
    max_failed_times:100000000;
    check_frequency: 10; # 每爬去多少次， 检测一次 QPS 限制
    ip_load_file: "data/ip_load"; # QPS 限制文件
  };

  proxy: {
    list : [
      "socks5://127.0.0.1:20000",
      "socks5://127.0.0.1:20001",
      "socks5://127.0.0.1:20002",
      "socks5://127.0.0.1:20003",
      "socks5://127.0.0.1:20004",
    ];
    max_successive_failures : 15;
    holdon_duration_after_failures: 60;
  };
};
