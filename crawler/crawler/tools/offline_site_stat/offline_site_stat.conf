#!/bin/bash

## saver_donelist records the latest output directory of links that crawled
crawler_saver_donelist=/user/pengdan/crawler_online/saver_donelist

## the site we need to stat.
## 应用程序将匹配所有的已经成功抓取的 URL ，如果某 URL 和 |site_list| 中
## 的某一个站点匹配（包含该站点名），则该站点抓取统计数加一
site_list="taobao,sina,sohu,baidu,hao123,google"
## 本次统计 hdfs 临时输出目录
hdfs_tmp_output_root_dir=/tmp/pengdan/offline_stat_site
## 程序运行完后,将本次运行的最终结果存放到目录
hdfs_final_output_root_dir=/user/pengdan/stat_data

hadoop_map_capacity=1000
hadoop_other_arg=""
